{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "from source.utils.config_manager import ConfigManager\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKGROUND_NOISE_DIRECTORY = os.path.join(ConfigManager().get_dataset_path(\n",
    "    'speech_recognition'), \"train\", \"audio\", \"_background_noise_\\\\\")\n",
    "SILENCE_DIRECTORY = os.path.join(ConfigManager().get_dataset_path(\n",
    "    'speech_recognition'), \"train\", \"audio\", \"silence\\\\\")\n",
    "TXT_FILES = os.path.join(ConfigManager().get_dataset_path(\n",
    "    'speech_recognition'), \"train\\\\\")\n",
    "FORMAT = \"wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isExist = os.path.exists(SILENCE_DIRECTORY)\n",
    "if not isExist:\n",
    "  os.makedirs(SILENCE_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_files(validation, test):\n",
    "    pd.Series(validation).to_csv(TXT_FILES+\"validation_silence.txt\",\n",
    "                                 header=None, index=None, sep='\\n', mode='a')\n",
    "    pd.Series(test).to_csv(TXT_FILES+\"test_silence.txt\",\n",
    "                           header=None, index=None, sep='\\n', mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_transformations_number = 4\n",
    "\n",
    "\n",
    "def generate_silence(size, validation_size=0.1, test_size=0.1):\n",
    "    \"\"\"\n",
    "    need to provide the size that's possible to be divided by 6 \n",
    "    \"\"\"\n",
    "    files_names = []\n",
    "    per_file_size = int(size/6)\n",
    "    for file_nr, file in enumerate(glob(BACKGROUND_NOISE_DIRECTORY + \"*.wav\")):\n",
    "        for i in tqdm(range(per_file_size)):\n",
    "            samples, sample_rate = torchaudio.load(file)\n",
    "            start = np.random.randint(len(samples[0]) - sample_rate, size=1)[0]\n",
    "            cutted = samples[:, start:start+sample_rate]\n",
    "            transformation = np.random.randint(\n",
    "                possible_transformations_number, size=1)[0]\n",
    "\n",
    "            if transformation == 0:\n",
    "                transform = transforms.Fade(\n",
    "                    fade_in_len=0, fade_out_len=sample_rate, fade_shape='linear')\n",
    "                cutted = transform(cutted)\n",
    "            elif transformation == 1:\n",
    "                transform = transforms.Vol(10)\n",
    "                cutted = transform(cutted)\n",
    "\n",
    "            elif transformation == 2:\n",
    "                noise = torch.tensor(np.random.normal(0, .05, cutted.shape))\n",
    "                cutted = torch.add(noise, cutted).to(dtype=torch.float32)\n",
    "            file_name = f\"{file_nr}_{i}_{transformation}.{FORMAT}\"\n",
    "            files_names.append(f\"silence/{file_name}\")\n",
    "            torchaudio.save(os.path.join(SILENCE_DIRECTORY,\n",
    "                            file_name), cutted, sample_rate, format=FORMAT)\n",
    "    files_names = np.array(files_names)\n",
    "    indexes = random.sample(list(range(len(files_names))), int(\n",
    "        (validation_size + test_size) * size))\n",
    "    validation_indexes = indexes[: int(validation_size * size)]\n",
    "    test_indexes = indexes[int(validation_size * size):]\n",
    "    save_files(files_names[validation_indexes], files_names[test_indexes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 135.52it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 228.55it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 242.72it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 252.62it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 236.25it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 257.80it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_silence(6000)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f596b1f1e2414a57cbac219f0e45f8be2c707cf8cf81cba26a1cb9bf52f74de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
